{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Redes Neurais.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q8uhcSodyju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUK_fJbDU69c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(xtrain, ytrain),(xtest,ytest) = fashion_mnist.load_data()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzpVmktUeW3t",
        "colab_type": "text"
      },
      "source": [
        "Essa tarefa é referente ao curso de deep learning e tensorflow 2.0. do Jones Granatyr.\n",
        "\n",
        "Basicamente é trabalhado em um dataset de roupas e acessórios onde o algoritmo deverá dizer qual tipo de roupa que é dentre a lista:\n",
        "\n",
        "\n",
        "0 - T-shirt/top\n",
        "\n",
        "1 - Trouser\n",
        "\n",
        "2 - Pullover\n",
        "\n",
        "3 - Dress\n",
        "\n",
        "4 - Coat\n",
        "\n",
        "5 - Sandal\n",
        "\n",
        "6 - Shirt\n",
        "\n",
        "7 - Sneaker\n",
        "\n",
        "8 - Bag\n",
        "\n",
        "9 - Ankle boot\n",
        "\n",
        "\n",
        "O dataset é divido entre 60.000 imagens de treino e mais 10.000 onde serão testadas o algoritmo\n",
        "\n",
        "Vamos começar!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5X-WGz4hc-n",
        "colab_type": "text"
      },
      "source": [
        "Cada imagem é composta de 28 x 28 pixels, onde cada pixel vai da cor 0 até 255, em tom monocromatico (preto e branco)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBqnoJPGbucR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e773a1c2-1f97-45cf-e0f5-dec0e09ba55b"
      },
      "source": [
        "xtrain[0].shape # representra o tamanho da imagem"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbpejNb-h8De",
        "colab_type": "text"
      },
      "source": [
        "Abaixo podemos verificar a primeira foto em formato numérico... cada um dos pontos é um pixel, 0 sendo branco , 255 sendo preto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB12WPRUh4Cv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7e8e7486-611b-468d-c75a-9ab2cfeb28bc"
      },
      "source": [
        "xtrain[0]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
              "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
              "          1,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
              "          0,   3],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
              "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
              "         10,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
              "         72,  15],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
              "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
              "        172,  66],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
              "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
              "        229,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
              "        173,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
              "        202,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
              "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
              "        209,  52],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
              "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
              "        167,  56],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
              "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
              "         92,   0],\n",
              "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
              "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
              "         77,   0],\n",
              "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
              "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
              "        159,   0],\n",
              "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
              "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
              "        215,   0],\n",
              "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
              "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
              "        246,   0],\n",
              "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
              "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
              "        225,   0],\n",
              "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
              "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
              "        229,  29],\n",
              "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
              "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
              "        230,  67],\n",
              "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
              "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
              "        206, 115],\n",
              "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
              "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
              "        210,  92],\n",
              "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
              "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
              "        170,   0],\n",
              "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
              "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeMGnLDZid4q",
        "colab_type": "text"
      },
      "source": [
        "Abaixo podemos ver como é a imagem, podemos fazer isso também com qualquer outra imagem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cG0qZoUc1pz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "50caa859-0e60-4ae8-95f9-ed562c6e1279"
      },
      "source": [
        "plt.imshow(xtrain[0], cmap = 'gray')\n",
        "print(f\"A classificação é o número: {ytrain[0]}\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A classificação é o número: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dET9PlfNi_Aq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "70d6afdd-3489-4a0f-f09b-704d2f674e0b"
      },
      "source": [
        "plt.imshow(xtrain[5], cmap = 'gray')\n",
        "print(f\"A classificação é o número: {ytrain[5]}\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A classificação é o número: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRgUm1-vlmwT",
        "colab_type": "text"
      },
      "source": [
        "No dataset xtrain e xtest ficam os pixels, no ytrain e ytest, o label de identificação de cada uma, por exemplo: shirt, bag, coat... \n",
        "\n",
        "Como podemos verificar a seguir:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVfyyAc_WWBs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "92b4f52a-2060-4909-fb17-2dc283bd412e"
      },
      "source": [
        "ytrain "
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMn51Tycl_Ca",
        "colab_type": "text"
      },
      "source": [
        "Para um melhor desempenho do algoritmo, devemos normalizar a imagem, ou seja, transformar todos os pixels entre o tamanho 0 e 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRPgZwsfXePt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain = xtrain / 255"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DrMeUNpXiYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtest = xtest / 255"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mZyQXGiXjvm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "45c817d1-a5e5-494f-daab-7ce5eec7dd53"
      },
      "source": [
        "xtrain[0]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
              "        0.05098039, 0.28627451, 0.        , 0.        , 0.00392157,\n",
              "        0.01568627, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00392157, 0.00392157, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01176471, 0.        , 0.14117647,\n",
              "        0.53333333, 0.49803922, 0.24313725, 0.21176471, 0.        ,\n",
              "        0.        , 0.        , 0.00392157, 0.01176471, 0.01568627,\n",
              "        0.        , 0.        , 0.01176471],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
              "        0.8       , 0.69019608, 0.5254902 , 0.56470588, 0.48235294,\n",
              "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.04705882, 0.03921569, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.60784314,\n",
              "        0.9254902 , 0.81176471, 0.69803922, 0.41960784, 0.61176471,\n",
              "        0.63137255, 0.42745098, 0.25098039, 0.09019608, 0.30196078,\n",
              "        0.50980392, 0.28235294, 0.05882353],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.27058824, 0.81176471,\n",
              "        0.8745098 , 0.85490196, 0.84705882, 0.84705882, 0.63921569,\n",
              "        0.49803922, 0.4745098 , 0.47843137, 0.57254902, 0.55294118,\n",
              "        0.34509804, 0.6745098 , 0.25882353],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.        , 0.78431373, 0.90980392,\n",
              "        0.90980392, 0.91372549, 0.89803922, 0.8745098 , 0.8745098 ,\n",
              "        0.84313725, 0.83529412, 0.64313725, 0.49803922, 0.48235294,\n",
              "        0.76862745, 0.89803922, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.71764706, 0.88235294,\n",
              "        0.84705882, 0.8745098 , 0.89411765, 0.92156863, 0.89019608,\n",
              "        0.87843137, 0.87058824, 0.87843137, 0.86666667, 0.8745098 ,\n",
              "        0.96078431, 0.67843137, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.75686275, 0.89411765,\n",
              "        0.85490196, 0.83529412, 0.77647059, 0.70588235, 0.83137255,\n",
              "        0.82352941, 0.82745098, 0.83529412, 0.8745098 , 0.8627451 ,\n",
              "        0.95294118, 0.79215686, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.01176471, 0.        , 0.04705882, 0.85882353, 0.8627451 ,\n",
              "        0.83137255, 0.85490196, 0.75294118, 0.6627451 , 0.89019608,\n",
              "        0.81568627, 0.85490196, 0.87843137, 0.83137255, 0.88627451,\n",
              "        0.77254902, 0.81960784, 0.20392157],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.02352941, 0.        , 0.38823529, 0.95686275, 0.87058824,\n",
              "        0.8627451 , 0.85490196, 0.79607843, 0.77647059, 0.86666667,\n",
              "        0.84313725, 0.83529412, 0.87058824, 0.8627451 , 0.96078431,\n",
              "        0.46666667, 0.65490196, 0.21960784],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.01568627,\n",
              "        0.        , 0.        , 0.21568627, 0.9254902 , 0.89411765,\n",
              "        0.90196078, 0.89411765, 0.94117647, 0.90980392, 0.83529412,\n",
              "        0.85490196, 0.8745098 , 0.91764706, 0.85098039, 0.85098039,\n",
              "        0.81960784, 0.36078431, 0.        ],\n",
              "       [0.        , 0.        , 0.00392157, 0.01568627, 0.02352941,\n",
              "        0.02745098, 0.00784314, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.92941176, 0.88627451, 0.85098039,\n",
              "        0.8745098 , 0.87058824, 0.85882353, 0.87058824, 0.86666667,\n",
              "        0.84705882, 0.8745098 , 0.89803922, 0.84313725, 0.85490196,\n",
              "        1.        , 0.30196078, 0.        ],\n",
              "       [0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.24313725,\n",
              "        0.56862745, 0.8       , 0.89411765, 0.81176471, 0.83529412,\n",
              "        0.86666667, 0.85490196, 0.81568627, 0.82745098, 0.85490196,\n",
              "        0.87843137, 0.8745098 , 0.85882353, 0.84313725, 0.87843137,\n",
              "        0.95686275, 0.62352941, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
              "        0.17254902, 0.32156863, 0.41960784, 0.74117647, 0.89411765,\n",
              "        0.8627451 , 0.87058824, 0.85098039, 0.88627451, 0.78431373,\n",
              "        0.80392157, 0.82745098, 0.90196078, 0.87843137, 0.91764706,\n",
              "        0.69019608, 0.7372549 , 0.98039216, 0.97254902, 0.91372549,\n",
              "        0.93333333, 0.84313725, 0.        ],\n",
              "       [0.        , 0.22352941, 0.73333333, 0.81568627, 0.87843137,\n",
              "        0.86666667, 0.87843137, 0.81568627, 0.8       , 0.83921569,\n",
              "        0.81568627, 0.81960784, 0.78431373, 0.62352941, 0.96078431,\n",
              "        0.75686275, 0.80784314, 0.8745098 , 1.        , 1.        ,\n",
              "        0.86666667, 0.91764706, 0.86666667, 0.82745098, 0.8627451 ,\n",
              "        0.90980392, 0.96470588, 0.        ],\n",
              "       [0.01176471, 0.79215686, 0.89411765, 0.87843137, 0.86666667,\n",
              "        0.82745098, 0.82745098, 0.83921569, 0.80392157, 0.80392157,\n",
              "        0.80392157, 0.8627451 , 0.94117647, 0.31372549, 0.58823529,\n",
              "        1.        , 0.89803922, 0.86666667, 0.7372549 , 0.60392157,\n",
              "        0.74901961, 0.82352941, 0.8       , 0.81960784, 0.87058824,\n",
              "        0.89411765, 0.88235294, 0.        ],\n",
              "       [0.38431373, 0.91372549, 0.77647059, 0.82352941, 0.87058824,\n",
              "        0.89803922, 0.89803922, 0.91764706, 0.97647059, 0.8627451 ,\n",
              "        0.76078431, 0.84313725, 0.85098039, 0.94509804, 0.25490196,\n",
              "        0.28627451, 0.41568627, 0.45882353, 0.65882353, 0.85882353,\n",
              "        0.86666667, 0.84313725, 0.85098039, 0.8745098 , 0.8745098 ,\n",
              "        0.87843137, 0.89803922, 0.11372549],\n",
              "       [0.29411765, 0.8       , 0.83137255, 0.8       , 0.75686275,\n",
              "        0.80392157, 0.82745098, 0.88235294, 0.84705882, 0.7254902 ,\n",
              "        0.77254902, 0.80784314, 0.77647059, 0.83529412, 0.94117647,\n",
              "        0.76470588, 0.89019608, 0.96078431, 0.9372549 , 0.8745098 ,\n",
              "        0.85490196, 0.83137255, 0.81960784, 0.87058824, 0.8627451 ,\n",
              "        0.86666667, 0.90196078, 0.2627451 ],\n",
              "       [0.18823529, 0.79607843, 0.71764706, 0.76078431, 0.83529412,\n",
              "        0.77254902, 0.7254902 , 0.74509804, 0.76078431, 0.75294118,\n",
              "        0.79215686, 0.83921569, 0.85882353, 0.86666667, 0.8627451 ,\n",
              "        0.9254902 , 0.88235294, 0.84705882, 0.78039216, 0.80784314,\n",
              "        0.72941176, 0.70980392, 0.69411765, 0.6745098 , 0.70980392,\n",
              "        0.80392157, 0.80784314, 0.45098039],\n",
              "       [0.        , 0.47843137, 0.85882353, 0.75686275, 0.70196078,\n",
              "        0.67058824, 0.71764706, 0.76862745, 0.8       , 0.82352941,\n",
              "        0.83529412, 0.81176471, 0.82745098, 0.82352941, 0.78431373,\n",
              "        0.76862745, 0.76078431, 0.74901961, 0.76470588, 0.74901961,\n",
              "        0.77647059, 0.75294118, 0.69019608, 0.61176471, 0.65490196,\n",
              "        0.69411765, 0.82352941, 0.36078431],\n",
              "       [0.        , 0.        , 0.29019608, 0.74117647, 0.83137255,\n",
              "        0.74901961, 0.68627451, 0.6745098 , 0.68627451, 0.70980392,\n",
              "        0.7254902 , 0.7372549 , 0.74117647, 0.7372549 , 0.75686275,\n",
              "        0.77647059, 0.8       , 0.81960784, 0.82352941, 0.82352941,\n",
              "        0.82745098, 0.7372549 , 0.7372549 , 0.76078431, 0.75294118,\n",
              "        0.84705882, 0.66666667, 0.        ],\n",
              "       [0.00784314, 0.        , 0.        , 0.        , 0.25882353,\n",
              "        0.78431373, 0.87058824, 0.92941176, 0.9372549 , 0.94901961,\n",
              "        0.96470588, 0.95294118, 0.95686275, 0.86666667, 0.8627451 ,\n",
              "        0.75686275, 0.74901961, 0.70196078, 0.71372549, 0.71372549,\n",
              "        0.70980392, 0.69019608, 0.65098039, 0.65882353, 0.38823529,\n",
              "        0.22745098, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
              "        0.28235294, 0.16078431, 0.1372549 , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0BY7VgqmrME",
        "colab_type": "text"
      },
      "source": [
        "Como possuímos 60.000 imagens com tamanho de 28 x 28, para podermos treinar o algoritmo devemos transformar em vetor, ou seja, (60 , 28 x 28)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZPYiBjRXlev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea9f5dad-f57a-4162-e21b-116ab4916ad3"
      },
      "source": [
        "xtrain.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWuYNzk_XrGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# como a dimensão de cada imagem é 28*28 mudamos toda a base de dados para o formato\n",
        "#[-1 todos os elementos, altura * largura]\n",
        "xtrain = xtrain.reshape(-1,28*28)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvHqcFwqYC-5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b9a88aa0-e074-4bf4-cd35-e502d5588fe1"
      },
      "source": [
        "xtrain.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2PVrfiXYGt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtest = xtest.reshape(-1,28*28)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tq35mSOYN2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "36e6ced5-b74f-42c7-fed5-048dcacc9304"
      },
      "source": [
        "xtest.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxo0JccRtU7G",
        "colab_type": "text"
      },
      "source": [
        "#**Construindo a rede neural artificial**:\n",
        "\n",
        "\n",
        "**Partindo do pressuposto do seguinte link:**\n",
        "\n",
        "https://iaexpert.academy/2020/05/04/quantas-camadas-escondidas-e-quantos-neuronios-incluir-numa-rede-neural-artificial/#:~:text=O%20n%C3%BAmero%20de%20neur%C3%B4nios%20escondidos%20deve%20ser%202%2F3,o%20dobro%20do%20tamanho%20da%20camada%20de%20entrada.\n",
        "\n",
        "**Temos:**\n",
        "\n",
        "1º - O número de neurônios escondidos deve estar entre o tamanho da camada de entrada e o da camada de saída. Usar o número médio entre as duas camadas é uma boa opção; ou seja... Uma camada oculta com 397 neurônios ((784 + 10)  /2) \n",
        "\n",
        "2º - O número de neurônios escondidos deve ser 2/3 do tamanho da camada de entrada, mais o tamanho da camada de saída. Assim a camada oculta deverá ter 522 neurônios\n",
        "\n",
        "3º - O número de neurônios escondidos deve ser menor que o dobro do tamanho da camada de entrada. Ou seja, a camada escondida deverá ter menos do que 1568 neurônios\n",
        "\n",
        "Parâmetros: \n",
        "Camada de entrada: 784 neurônios\n",
        "\n",
        "Camada oculta: 397 ~ 1568 (serão feitos testes com 397,522 e outro com valor de 700)\n",
        "\n",
        "Utilização do Droupout de 0.2 para zerar o valor de 20% dos neurônios \n",
        "\n",
        "Camada de Saída: 10 neurônios pois a quantidade de classes para serem previstas são de 10\n",
        "\n",
        "\n",
        "\n",
        "Modelo de ativação da camada de saída: 'softmax' pois existem mais de 2 classes para serem definidas\n",
        "\n",
        "Modelo de ativação das demais camadas: 'relu'\n",
        "\n",
        "\n",
        "**------------------------Teste 1--------------------------------**\n",
        "\n",
        "Uma camada oculta com 397 neurônios ((784 + 10)  /2) \n",
        "\n",
        "Epoch 12\n",
        "\n",
        "model = tf.keras.models.Sequential() \n",
        "\n",
        "model.add(tf.keras.layers.Dense(units = 397, activation = \"relu\", input_shape=(784,)))\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=10, activation = \"softmax\")) #adicionando a camada de saída\n",
        "\n",
        "Test accuracy: 0.885200023651123\n",
        "\n",
        "**------------------------Teste 2--------------------------------**\n",
        "\n",
        "Uma camada oculta com 522 neurônios\n",
        "\n",
        "Epoch = 12\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units = 522, activation = \"relu\", input_shape=(784,))) \n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=10, activation = \"softmax\")) \n",
        "\n",
        "Test accuracy: 0.8902945968978128\n",
        "\n",
        "\n",
        "**-------------------------Teste 3 --------------------------------**\n",
        "\n",
        "Uma camada oculta com 700 neurônios\n",
        "\n",
        "Epoch = 12\n",
        "\n",
        "model = tf.keras.models.Sequential() \n",
        "model.add(tf.keras.layers.Dense(units = 700, activation = \"relu\", input_shape=(784,))) #camada de entrada + camada oculta\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(units=10, activation = \"softmax\")) \n",
        "\n",
        "Test accuracy: 0.8833000063896179\n",
        "\n",
        "\n",
        "**------------------------Teste 4-----------------------------------**\n",
        "\n",
        "Duas camadas ocultas de 397 neurônios, 12 epochs\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units = 397, activation = \"relu\", input_shape=(784,)))\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units = 397, activation = \"relu\", input_shape=(784,))) \n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=10, activation = \"softmax\")) \n",
        "\n",
        "Test accuracy: 0.8792999982833862\n",
        "\n",
        "\n",
        "**---------------------------Teste 5-----------------------------------**\n",
        "\n",
        "Duas camadas ocultas de 522 neurônios, 12 epochs\n",
        "\n",
        "model = tf.keras.models.Sequential() \n",
        "\n",
        "model.add(tf.keras.layers.Dense(units = 522, activation = \"relu\", input_shape=(784,)))\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units = 522, activation = \"relu\", input_shape=(784,)))\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=10, activation = \"softmax\")) \n",
        "\n",
        "Test accuracy: 0.8866999745368958\n",
        "\n",
        "**---------------------------Teste 6 -----------------------------------**\n",
        "\n",
        "Duas camadas ocultas de 522 neurônios, 12 epochs\n",
        "\n",
        "model = tf.keras.models.Sequential() \n",
        "\n",
        "model.add(tf.keras.layers.Dense(units = 522, activation = \"relu\", input_shape=(784,))) #camada de entrada + camada oculta\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units = 522, activation = \"relu\", input_shape=(784,))) \n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=10, activation = \"softmax\"))\n",
        "\n",
        "\n",
        "Test accuracy: 0.8851000070571899\n",
        "\n",
        "\n",
        "**-------------------------Teste 7 ----------------------------------**\n",
        "\n",
        "mesmos parâmetros do teste 2, porém com epoch = 15\n",
        "\n",
        "model = tf.keras.models.Sequential() \n",
        "\n",
        "model.add(tf.keras.layers.Dense(units = 522, activation = \"relu\", input_shape=(784,))) \n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=10, activation = \"softmax\"))\n",
        "\n",
        "Test accuracy: 0.8925999999046326\n",
        "\n",
        "\n",
        "**-------------------------Teste 8 ----------------------------------**\n",
        "\n",
        "mesmos parâmetros do teste 2, porém com epoch = 10\n",
        "\n",
        "model = tf.keras.models.Sequential() \n",
        "model.add(tf.keras.layers.Dense(units = 522, activation = \"relu\", input_shape=(784,))) \n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(units=10, activation = \"softmax\"))\n",
        "\n",
        "Test accuracy: 0.8841000199317932\n",
        "\n",
        "**Ou seja, os melhores parâmetros foram do teste 2 e do teste 7**\n",
        "**Realizei todos os testes com os parâmetros anteriores, então a seguir utilizarei apenas os melhores parâmetros, que são referentes ao teste 7**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE8FX-cFldHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Parametros do teste 7\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units = 522, activation = \"relu\", input_shape=(784,)))\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(units=10, activation = \"softmax\"))"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVuxMuSUZ02A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
        "              metrics =['sparse_categorical_accuracy'])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgRoY2IZA-Lp",
        "colab_type": "text"
      },
      "source": [
        "O sumário a seguir demonstra como se encontra a nossa rede neural atual\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrBu_VU8bjg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "45c100ed-ee0b-47fb-b7cb-035c1ebb729a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 522)               409770    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 522)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                5230      \n",
            "=================================================================\n",
            "Total params: 415,000\n",
            "Trainable params: 415,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIFuHFK7BUAL",
        "colab_type": "text"
      },
      "source": [
        "Treinamento da nossa rede neural, com os parâmetros passados anteriormente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShSPofM8blif",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "7787d1ca-9899-4b44-94a1-c8d658b36fa6"
      },
      "source": [
        "model.fit(xtrain,ytrain,epochs=15)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4995 - sparse_categorical_accuracy: 0.8199\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3844 - sparse_categorical_accuracy: 0.8581\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3508 - sparse_categorical_accuracy: 0.8701\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3308 - sparse_categorical_accuracy: 0.8782\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3161 - sparse_categorical_accuracy: 0.8849\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3008 - sparse_categorical_accuracy: 0.8878\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2881 - sparse_categorical_accuracy: 0.8933\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2814 - sparse_categorical_accuracy: 0.8947\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2737 - sparse_categorical_accuracy: 0.8974\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2606 - sparse_categorical_accuracy: 0.9017\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2564 - sparse_categorical_accuracy: 0.9024\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2482 - sparse_categorical_accuracy: 0.9068\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2432 - sparse_categorical_accuracy: 0.9084\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2375 - sparse_categorical_accuracy: 0.9094\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2303 - sparse_categorical_accuracy: 0.9125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3dc1b1fb00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87fZGQKcb_p_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5879bd3d-45cb-4ffb-8bde-8e5f52df4bbe"
      },
      "source": [
        "test_loss , test_accuracy = model.evaluate(xtest,ytest)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3250 - sparse_categorical_accuracy: 0.8926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15cnLjs6E7rU",
        "colab_type": "text"
      },
      "source": [
        "O algoritmo deu uma precisão de 89,25% em todas as 10 mil imagens testadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqUcNKiwcZIZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "648cb40f-5cac-4d4e-9e96-f6f1cc5c5b36"
      },
      "source": [
        "print(f\"Test accuracy: {test_accuracy}\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8925999999046326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNeyac5wckcb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "add3bed5-77a8-47a1-985e-1578a562582d"
      },
      "source": [
        "test_loss"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.32501065731048584"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yVFz0mkcnrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}